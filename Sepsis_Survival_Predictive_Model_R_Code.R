#############################################################
########          POC R Studio on MS Azure           ########
########          Sepsis Survival Predictive Model   ######## 
########                April 2022                   ######## 
#############################################################

#Access Azure Portal - Storage Account and Read files
#Data Wrangling and Predictive Model
#Step 1 - Include Azure profile
source("C:/dev/Rprofile.R")
#Step 2 - Invoke necessary libraries for analyses and modeling.
library(AzureStor)    #Manage storage in Microsoft's 'Azure' cloud
library(AzureRMR)     #Interface to 'Azure Resource Manager'
library(psych)        #A general purpose toolbox for personality, psychometric theory and experimental psychology. Functions are primarily for multivariate analysis. 
library(ggplot2) 	    #A system for creating graphics, based on "The Grammar of Graphics". 
library(caret) 		    #Misc functions for training and plotting classification and regression models.
library(rpart) 		    #Recursive partitioning for classification, regression and survival trees.  
library(rpart.plot) 	#Plot 'rpart' models. Extends plot.rpart() and text.rpart() in the 'rpart' package.
library(RColorBrewer) #Provides color schemes for maps (and other graphics). 
library(party)		    #A computational toolbox for recursive partitioning.
library(partykit)	    #A toolkit with infrastructure for representing, summarizing, and visualizing tree-structure.
library(pROC) 		    #Display and Analyze ROC Curves.
library(ISLR)		      #Collection of data-sets used in the book 'An Introduction to Statistical Learning with Applications in R.
library(randomForest)	#Classification and regression based on a forest of trees using random inputs.
library(dplyr)		    #A fast, consistent tool for working with data frame like objects, both in memory and out of memory.
library(ggraph)		    #The grammar of graphics as implemented in ggplot2 is a poor fit for graph and network visualizations.
library(igraph)		    #Routines for simple graphs and network analysis.
library(mlbench) 	    #A collection of artificial and real-world machine learning benchmark problems, including, e.g., several data sets from the UCI repository.
library(GMDH2)		    #Binary Classification via GMDH-Type Neural Network Algorithms.
library(apex)		      #Toolkit for the analysis of multiple gene data. Apex implements the new S4 classes 'multidna'.
library(mda)		      #Mixture and flexible discriminant analysis, multivariate adaptive regression splines.
library(WMDB)		      #Distance discriminant analysis method is one of classification methods according to multiindex.
library(klaR)		      #Miscellaneous functions for classification and visualization, e.g. regularized discriminant analysis, sknn() kernel-density naive Bayes...
library(kernlab)	    #Kernel-based machine learning methods for classification, regression, clustering, novelty detection.
library(readxl)    	  #n Import excel files into R. Supports '.xls' via the embedded 'libxls' C library.                                                                                                                                                                 
library(GGally)  	    #The R package 'ggplot2' is a plotting system based on the grammar of graphics.                                                                                                                                                                  
library(mctest)		    #Package computes popular and widely used multicollinearity diagnostic measures.
library(sqldf)		    #SQL for dataframe wrangling.
library(reshape2)     #Pivoting table
library(anytime)      #Caches TZ in local env
library(survey)       #Summary statistics, two-sample tests, rank tests, glm.... 
library(mice)         #Library for multiple imputation
library(MASS)         #Functions and datasets to support Venables and Ripley
library(rjson)        #Load the package required to read JSON files.
library(RISmed)       #RISmed is a portmanteau of RIS (for Research Information Systems, a common tag format for bibliographic data) and PubMed.
library(wordcloud)    #Word visualization
library(tm)
library(tmap)

#Apply credentials from profile
az <- create_azure_login(tenant=Azure_tenantID)

# same as above
blob_endp <- blob_endpoint("https://olastorageac.blob.core.windows.net/",key=Azure_Storage_Key)
file_endp <- file_endpoint("https://olastorageac.file.core.windows.net/",key=Azure_Storage_Key)

#An existing container
sepsis_data <- blob_container(blob_endp, "sepsis")

# list blobs inside a blob container
list_blobs(sepsis_data)

#Temp download of files needed for data wrangling
storage_download(sepsis_data, "sepsis_data.csv", "~/sepsis_data.csv")

#Read csv in memory
sepsis_data<-read.csv("sepsis_data.csv")

#Delete Temp downloaded of files
file.remove("sepsis_data.csv")

#Data cleaning and wrangling to get features required for modeling
#Number of columns
ncol(sepsis_data)
#Number of rows
nrow(sepsis_data)
#View fields in files
names(sepsis_data)
#View subset of file
head(sepsis_data,2)
#View structure of file
str(sepsis_data)

#Step 3
#Descriptive Statistics 
summary(sepsis_data)
#Check for missingness
sapply(sepsis_data, function(x) sum(is.na(x)))
sepsis_data <- sepsis_data[complete.cases(sepsis_data), ]

#Step 4
#Modeling
#Setting the random seed for replication
set.seed(43)
df<-sepsis_data

#Step 5
#setting up cross-validation
cv_control <- trainControl(method="repeatedcv", number = 10, allowParallel=TRUE)


#random sample half the rows 
newsample = sample(dim(df)[1], dim(df)[1]/2) # half of sample
#create training and test data sets
df_train = df[newsample, ]
df_test = df[-newsample, ]

#Random Forests
#Random Forest for Classification Trees using method="rf"
#Assumptions
#a.No formal distributional assumptions, random forests are non-parametric and can thus handle skewed and multi-modal data.
#I..Forward Propagation...
trainingmodelranfor <- train(as.factor(hospital_outcome_1alive_0dead) ~ ., data=df_train,method="rf",trControl=cv_control, importance=TRUE)
trainingmodelranfor 
#Get class predictions for training dataset
classtrainranfor <-  predict(trainingmodelranfor, type="raw")
head(classtrainranfor)

#Get class predictions for test dataset
classtestranfor <-  predict(trainingmodelranfor, newdata = df_test, type="raw")
head(classtestranfor)
#Derive predicted probabilites for test dataset
probsranfor=predict(trainingmodelranfor, newdata=df_test, type="prob")
head(probsranfor)
#Compute ROC 
rocranfor <- roc(df_test$hospital_outcome_1alive_0dead,probsranfor[,"1"])
rocranfor
#The ROC curve
plot(rocranfor,col=c(3))
##Compute area under curve (Closer to 1 is preferred)
auc(rocranfor)
#confusionmatrix
confusionmatrixranfor<-confusion(predict(trainingmodelranfor, df_train), df_train$hospital_outcome_1alive_0dead)
confusionmatrixranfor
#Overall Misclassification Rate
errorrateranfor<-(1-sum(diag(confusionmatrixranfor))/sum(confusionmatrixranfor))
errorrateranfor
#Sensitivity and Specificity
# Sensitivity - aka true positive rate, the recall, or probability of detection
sensitivityranfor<-sensitivity(confusionmatrixranfor)
sensitivityranfor
## Specificity - aka true negative rate
specificityranfor<-specificity(confusionmatrixranfor)
specificityranfor
#prediction
predranfor<-data.frame(classtestranfor)
predranfor <- cbind(df_test, predranfor)
probsranfor_likelihood <-data.frame(probsranfor)
predranfor_train <- cbind(predranfor,probsranfor_likelihood)
#Write output of prediction to csv 
write.csv(predranfor_train, file = "Prediction_ranfor2a.csv")

#II..Backward Propagation...
testmodelranfor <- train(as.factor(hospital_outcome_1alive_0dead) ~ ., data=df_test,method="rf",trControl=cv_control, importance=TRUE)
testmodelranfor 
#Get class predictions for test dataset
classtestranfor <-  predict(testmodelranfor, type="raw")
head(classtestranfor)
#Get class predictions for training dataset
classtrainranfor <-  predict(testmodelranfor, newdata = df_train, type="raw")
head(classtrainranfor)
#Derive predicted probabilites for training dataset
probsranfor=predict(testmodelranfor, newdata=df_train, type="prob")
head(probsranfor)
#Compute ROC 
rocranfor <- roc(df_train$hospital_outcome_1alive_0dead,probsranfor[,"1"])
rocranfor
#The ROC curve
plot(rocranfor,col=c(3))
##Compute area under curve (Closer to 1 is preferred)
auc(rocranfor)
#confusionmatrix
confusionmatrixranfor<-confusion(predict(testmodelranfor, df_test), df_test$hospital_outcome_1alive_0dead)
confusionmatrixranfor
# Overall Misclassification Rate
errorrateranfor<-(1-sum(diag(confusionmatrixranfor))/sum(confusionmatrixranfor))
errorrateranfor
#Sensitivity and Specificity
# Sensitivity - aka true positive rate, the recall, or probability of detection
sensitivityranfor<-sensitivity(confusionmatrixranfor)
sensitivityranfor
## Specificity - aka true negative rate
specificityranfor<-specificity(confusionmatrixranfor)
specificityranfor
#prediction
predranfor<-data.frame(classtrainranfor)
predranfor <- cbind(df_train, predranfor)
probsranfor_likelihood <-data.frame(probsranfor)
predranfor_test <- cbind(predranfor,probsranfor_likelihood)
#Write output of prediction to csv 
write.csv(predranfor_test, file = "Prediction_ranfor2b.csv")

#Rename column where names is...
names(predranfor_test)[names(predranfor_test) == "classtrainranfor"] <- "PREDICTION"
names(predranfor_train)[names(predranfor_train) == "classtestranfor"] <- "PREDICTION"

#Row bind the two dataframes
predranfor_all<-rbind(predranfor_test,predranfor_train)

#Column bind the new two dataframes
Final_Result_sepsis<-predranfor_all

#Write output of prediction to csv 
write.csv(Final_Result_sepsis, file = "Final_Result_sepsis.csv")

#Regrouping Original...
Survived<-sqldf("select distinct age_years,sex_0male_1female,episode_number,count(*) as Survived  from Final_Result_sepsis where hospital_outcome_1alive_0dead=1
                group by age_years,sex_0male_1female,episode_number")
Died<-sqldf("select distinct age_years,sex_0male_1female,episode_number,count(*) as Died  from Final_Result_sepsis where hospital_outcome_1alive_0dead=0
                group by age_years,sex_0male_1female,episode_number")
Combined<-sqldf("select x.*, y.Died from Survived x left join Died y
                on x.age_years=y.age_years and x.sex_0male_1female=y.sex_0male_1female and
                x.episode_number=y.episode_number")
#Replace NAs with 0
Combined_new<-Combined %>% replace(is.na(.), 0)

Combined_Rate<-sqldf("select x.*,(1-(x.Died/(x.Survived+x.Died))) as Survival_Rate_Original from Combined_new x")


#Regrouping Prediction...
Survived_p<-sqldf("select distinct age_years,sex_0male_1female,episode_number,count(*) as Survived  from Final_Result_sepsis where PREDICTION=1
                group by age_years,sex_0male_1female,episode_number")
Died_p<-sqldf("select distinct age_years,sex_0male_1female,episode_number,count(*) as Died  from Final_Result_sepsis where PREDICTION=0
                group by age_years,sex_0male_1female,episode_number")
Combined_p<-sqldf("select x.*, y.Died from Survived_p x left join Died_p y
                on x.age_years=y.age_years and x.sex_0male_1female=y.sex_0male_1female and
                x.episode_number=y.episode_number")
#Replace NAs with 0
Combined_new_p<-Combined_p %>% replace(is.na(.), 0)

Combined_Rate_p<-sqldf("select x.*,(1-(x.Died/(x.Survived+x.Died))) as Survival_Rate_Prediction from Combined_new_p x")

#Original and Prediction
Chart<-sqldf("select x.age_years as Age,x.sex_0male_1female as Gender,x.episode_number,x.Survival_Rate_Original,y.Survival_Rate_Prediction from Combined_Rate x left join Combined_Rate_p y
                on x.age_years=y.age_years and x.sex_0male_1female=y.sex_0male_1female and
                x.episode_number=y.episode_number")

write.csv(Chart, file = "Chart.csv")






#Write output of prediction to csv 
write.csv(Chart, file = "Chart.csv")
#Creating the data for JSON file
jsonData <- toJSON(Chart)
write(Chart,"Chart.json")

#Upload Model results data into container in Azure
cont_upload <- blob_container(blob_endp, "modeloutput")
#upload_blob(cont_upload, src="C:\\Users\\olajideajayi\\OneDrive - Microsoft\\Documents\\Chart.csv")
upload_blob(cont_upload, src="C:\\Users\\olajideajayi\\OneDrive - Microsoft\\Documents\\Chart.json")

#Remove Azure Credentials from environment after use 
rm(Azure_SubID) 
rm(Azure_Storage_Key)
rm(Azure_tenantID)
rm(Azure_ResourceGrp)
